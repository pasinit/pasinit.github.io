-
  layout: paper
  paper-type: inproceedings
  selected: y
  year: 2020
  img: ijcai2020
  title: "With More Contexts Comes Better Performance: Contextualized Sense Embeddings for All-Round Word SenseDisambiguation"
  authors: "Bianca Scarlini, <strong>Tommaso Pasini</strong> and Roberto Navigli"
  booktitle: Proceedings of the Conference on Epirical Methods for Natural Language Processing (EMNLP-2020).
  doc-url:
  venue: conference\
  abstract: >
    Contextualized word embeddings have been employed effectively across several tasks in Natural Language Processing,
    as they have proved to carry useful semantic information.
    However, it is still hard to link them to structured sources of knowledge.
    In this paper we present ARES (context-AwaRe Embeddings of Senses), a semi-supervised approach to producing sense
    embeddings for the lexical meanings within a lexical knowledge base that lie in a space that is comparable to that
    of contextualized word vectors.
    ARES representations enable a simple 1-Nearest-Neighbour algorithm to outperform state-of-the-art models, not only
    in the English Word Sense Disambiguation task, but also in the multilingual one, whilst training on sense-annotated
    data in English only.
    We further assess the quality of our embeddings in the Word-in-Context task, where, when used as an external source
    of knowledge, they consistently improve the performance of a neural model, leading it to compete with other more
    complex architectures.
    ARES embeddings for all WordNet concepts and the automatically-extracted contexts used for creating the sense
    representations are freely available at http://sensembert.org/ares.
  bibtex: |
    @inproceedings{scarlini-et-al-2020-ares,
      title     = {{With More Contexts Comes Better Performance: Contextualized Sense Embeddings for All-Round Word SenseDisambiguation}},<br/>
      author    = {Scarlini, Bianca and, Pasini, Tommaso and Navigli, Roberto}, <br/>
      booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP-2020)},<br/>
      publisher = {Association for Computational Linguistics},<br/>
      year      = {2020},<br/>
    }

-
  layout: paper
  paper-type: inproceedings
  selected: y
  year: 2020
  img: ijcai2020
  title: "XL-WiC: A Multilingual Benchmarkfor Evaluating Semantic Contextualization"
  authors: "Alessandro Raganato*, <strong>Tommaso Pasini*</strong>, Jose Camacho-Collados and Mohammad Taher Pilehvar"
  booktitle: Proceedings of the Conference on Epirical Methods for Natural Language Processing (EMNLP-2020).
  doc-url:
  venue: conference\
  abstract: >
    The ability to correctly model distinct meanings of a word is crucial for the effectiveness of semantic representation techniques.
    However, most existing evaluation benchmarks for assessing this criterion are tied to sense inventories (usually WordNet), restricting their usage to a small subset of knowledge-based representation techniques.
    The Word-in-Context dataset (WiC) addresses the dependence on sense inventories by reformulating the standard disambiguation task as a binary classification problem; but, it is limited to the English language.
    We put forward a large multilingual benchmark, XL-WiC, featuring gold standards in 12 new languages from varied language families and with different degrees of resource availability, opening room for evaluation scenarios such as zero-shot cross-lingual transfer.
    We perform a series of experiments to determine the reliability of the datasets and to set performance baselines for several recent contextualized multilingual models.
    Experimental results show that even when no tagged instances are available for a target language, models trained solely on the English data can attain competitive performance in the task of distinguishing different meanings of a word, even for distant languages.
    XL-WiC is available at https://pilehvar.github.io/xlwic/.
  bibtex: |
    @inproceedings{raganato-et-al-2020-xlwic,
      title     = {{XL-WiC: A Multilingual Benchmarkfor Evaluating Semantic Contextualization}},<br/>
      author    = {Raganato, Alessandro and Pasini, Tommaso and Camacho-Collados, Jose and Taher Pilehvar, Mohammad}, <br/>
      booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP-2020)},<br/>
      publisher = {Association for Computational Linguistics},<br/>
      year      = {2020},<br/>
    }

-
  layout: paper
  paper-type: inproceedings
  selected: y
  year: 2019
  img: acl2019
  title: "SensEmBERT:Context-Enhanced Sense Embeddings for Multilingual Word Sense Disambiguation"
  authors: "Bianca Scarlini, <strong>Tommaso Pasini</strong> and Roberto Navigli"
  booktitle: Proceedings of AAAI.
  #doc-url: https://www.aclweb.org/anthology/P19-1069.pdf
  venue: conference\
  abstract: >
    Contextual representations of words derived by neural language models have proven to effectively encode the subtle distinctions
    that might occur between different meanings of the same word. However, these representations are not tied to a semantic network,
    hence they leave the word meanings implicit and thereby neglect the information that can be derived from the knowledge base itself.
    In this paper, we propose SensEmBERT, a knowledge-based approach that brings together the expressive power of language modelling and
    the vast amount of knowledge contained in a semantic network to produce high-quality latent semantic representations of word meanings in multiple languages.
    Our vectors lie in a space comparable with that of contextualized word embeddings, thus allowing a word occurrence to be easily linked to
    its meaning by applying a simple nearest neighbour approach.
    We show that, whilst not relying on manual semantic annotations, SensEmBERT is able to either achieve or surpass state-of-the-art
    results attained by most of the supervised neural approaches on the English Word Sense Disambiguation task.
    When scaling to other languages, our representations prove to be equally effective as their English counterpart and
    outperform the existing state of the art on all the Word Sense Disambiguation multilingual datasets.
    The embeddings are released in five different languages at http://sensembert.org.
  bibtex: >
    @inproceedings{scarlini-etal-2020,
        title = "{{SensEmBERT:Context-Enhanced Sense Embeddings for Multilingual Word Sense Disambiguation}}",
        author = "Scarlini, Bianca  and
          Pasini, Tommaso  and
          Navigli, Roberto",
        booktitle = "Proceedings of AAAI",
        month = Feb,
        year = "2020",
        address = "New York, USA",
        publisher = "AAAI",
    }
-layout: paper
  paper-type: inproceedings
  selected: y
  year: 2020
  img: acl2020
  title: "CSI: A Coarse Sense Inventory for 85% Word Sense Disambiguation"
  authors: "Caterina Lacerra, Michele Bevilacqua, <strong>Tommaso Pasini</strong> and Roberto Navigli"
  booktitle: Proceedings of AAAI.
  #doc-url: https://www.aclweb.org/anthology/P19-1069.pdf
  venue: conference\
  abstract: >
    Word Sense Disambiguation (WSD) is the task of associating a word in context with one of its meanings. While many
    works in the past have focused on raising the state of the art, none has even come close to achieving an F-score
    in the 80% ballpark when using WordNet as its sense inventory.
    We contend that one of the main reasons for this failure is the excessively fine granularity of this inventory,
    resulting in senses that are hard to differentiate between, even for an experienced human annotator.
    In this paper we cope with this long-standing problem by introducing Coarse Sense Inventory (CSI),
    obtained by linking WordNet concepts to a new set of 45 labels. The results show that the coarse granularity of CSI
    leads a WSD model to achieve 85.9% F1, while maintaining a high expressive power. Our set of labels also exhibits
    ease of use in tagging and a descriptiveness that other coarse inventories lack, as demonstrated in two annotation
    tasks which we performed. Moreover, a few-shot evaluation proves that the class-based nature of CSI allows the model
    to generalise over unseen or under-represented words.
  bibtex: >
    @inproceedings{lacerra-etal-2020,
        title = "{{CSI: A Coarse Sense Inventory for 85% Word Sense Disambiguation}}",
        author = "Lacerra, Caterina and Bevilacqua, Michele and Pasini, Tommaso  and
          Navigli, Roberto",
        booktitle = "Proceedings of AAAI",
        month = Feb,
        year = "2020",
        address = "New York, USA",
        publisher = "AAAI",
    }
-
  layout: paper
  paper-type: inproceedings
  selected: y
  year: 2020
  img: LREC2020
  title: "Sense-Annotated Corpora for Word Sense Disambiguation in Multiple Languages and Domains"
  authors: "Bianca Scarlini, <strong>Tommaso Pasini</strong> and Roberto Navigli"
  booktitle: Proceedings of LREC 2020.
  doc-url: http://trainomatic.org/data/LREC_2020_Scarlinietal.pdf
  venue: conference\
  abstract: >
    The knowledge acquisition bottleneck problem dramatically hampers the creation of sense-annotated
    data for Word Sense Disambiguation (WSD). Sense-annotated data are scarce for English and almost absent
    for other languages. This limits the range of action of deeplearning approaches, which today are at the
    base of any NLP task and are hungry for data. We mitigate this issue and encourage further research in
    multilingual WSD by releasing to the NLP community five large datasets annotated with word senses in five
    different languages, namely, English, French, Italian, German and Spanish, and 5 distinct datasets in
    English, each for a different semantic domain. We show that supervised WSD models trained on our data
    attain higher performance than when trained on other automaticallycreated corpora. We release all our
    data containing more than 15 million annotated instances in 5 different languages at http://trainomatic.org/onesec.
  bibtex: |
    @inproceedings{scarlini-etal-2020,<br/>
        title = {{Sense-Annotated Corpora for Word Sense Disambiguation in Multiple Languages and Domains}},<br/>
        author = "Scarlini, Bianca and Pasini, Tommaso and Navigli, Roberto",<br/>
        booktitle = "Proceedings of LREC",<br/>
        month = May,<br/>
        year = "2020",<br/>
        address = "Virtual",<br/>
        publisher = "LRE"<br/>
    }

-
  layout: paper
  paper-type: inproceedings
  selected: y
  year: 2020
  img: LREC2020
  title: "A Short Survey on Sense-Annotated Corpora"
  authors: "<strong>Tommaso Pasini</strong> and Jose Camacho-Collados"
  booktitle: Proceedings of LREC 2020.
  doc-url: https://arxiv.org/abs/1802.04744
  venue: conference\
  abstract: >
    Large sense-annotated datasets are increasingly necessary for training deep supervised systems in Word Sense Disambiguation. However, gathering high-quality sense-annotated data for as many instances as possible is a laborious and expensive task. This has led to the proliferation of automatic and semi-automatic methods for overcoming the so-called knowledge-acquisition bottleneck. In this short survey we present an overview of sense-annotated corpora, annotated either manually- or (semi)automatically, that are currently available for different languages and featuring distinct lexical resources as inventory of senses, i.e. WordNet, Wikipedia, BabelNet. Furthermore, we provide the reader with general statistics of each dataset and an analysis of their specific features.
  bibtex: |
    @inproceedings{pasini-and-camachocollados-2020,<br/>
        title = {{A Short Survey on Sense-Annotated Corpora}},<br/>
        author = {Pasini, Tommaso and Camacho-Collados, Jose},<br/>
        booktitle = "Proceedings of LREC",<br/>
        month = May,<br/>
        year = "2020",<br/>
        address = "Virtual",<br/>
        publisher = "LRE"<br/>
    }
-
  layout: paper
  paper-type: inproceedings
  selected: y
  year: 2020
  img: acl2020
  title: "CluBERT: A Cluster-Based Approach for Learning Sense Distributions in Multiple Languages"
  authors: "<strong>Tommaso Pasini</strong>, Federico Scozzafava and Bianca Scarlini"
  booktitle: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.
  doc-url: https://www.researchgate.net/publication/341151563_CluBERT_A_Cluster-Based_Approach_for_Learning_Sense_Distributions_in_Multiple_Languages
  venue: conference\
  abstract: >
    Knowing the Most Frequent Sense (MFS) of a word has been proved to help Word Sense Disambiguation (WSD)
    models significantly. However, the scarcity of sense-annotated data makes it difficult to induce a reliable
    and high-coverage distribution of the meanings in a language vocabulary.
    To address this issue, in this paper we present CluBERT, an automatic and multilingual approach for inducing
    the distributions of word senses from a corpus of raw sentences.
    Our experiments show that CluBERT learns distributions over English senses that are of higher quality than
    those extracted by alternative approaches.
    When used to induce the MFS of a lemma, CluBERT attains state-of-the-art results on the English Word Sense
    Disambiguation tasks and helps to improve the disambiguation performance of two off-the-shelf WSD models.
    Moreover, our distributions also prove to be effective in other languages, beating all their alternatives
    for computing the MFS on the multilingual WSD tasks.
    We release our sense distributions in five different languages at https://github.com/SapienzaNLP/clubert.
  bibtex: |
    @inproceedings{pasini-etal-2020,<br/>
        title = {{CluBERT: A Cluster-Based Approach for Learning Sense Distributions in Multiple Languages}},<br/>
        author = {Pasini, Tommaso and Scozzafava, Federico, and Scarlini, Bianca},<br/>
        booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},<br/>
        year = {2020},<br/>
        month = {Jul}, <br/>
        address = {Virtual},<br/>
        publisher = {Association for Computational Linguistics}<br/>
    }