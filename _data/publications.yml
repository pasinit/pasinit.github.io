-
  layout: paper
    paper-type: inproceedings
    selected: y
    year: 2020
    img: ijcai2020
    title: "The Knowledge Acquisition Bottleneck Problem in Multilingual Word Sense Disambiguation"
    authors: "<strong>Tommaso Pasini</strong>"
    booktitle: Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence (IJCAI-2020).
    doc-url: https://www.researchgate.net/publication/342878102_The_Knowledge_Acquisition_Bottleneck_Problem_in_Multilingual_Word_Sense_Disambiguation
    venue: conference\
    abstract: >
      Word Sense Disambiguation (WSD) is the task of identifying the meaning of a word in a given context.
      It lies at the base of Natural Language Processing as it provides semantic information for words. In the last
      decade, great strides have been made in this field and much effort has been devoted to mitigate the knowledge
      acquisition bottleneck problem, i.e., the problem of semantically annotating texts at a large scale and in different
      languages. This issue is ubiquitous in WSD as it hinders the creation of both multilingual knowledge bases and
      manually-curated training sets. In this work, we first introduce the reader to the task of WSD through a short
      historical digression and then take the stock of the advancements to alleviate the knowledge acquisition bottleneck
      problem. In that, we survey the literature on manual, semi-automatic and automatic approaches to create English and
      multilingual corpora tagged with sense annotations and present a clear overview over supervised models for WSD.
      Finally, we provide our view over the future directions that we foresee for the field.
    bibtex: |
      @inproceedings{pasini-2020-bottleneck-wsd-survey,
        title     = {{The Knowledge Acquisition Bottleneck Problem in Multilingual Word Sense Disambiguation}},<br/>
        author    = {Pasini, Tommaso}, <br/>
        booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
                     Artificial Intelligence, {IJCAI-20}},<br/>
        publisher = {International Joint Conferences on Artificial Intelligence Organization},<br/>
        pages     = {4936--4942},<br/>
        year      = {2020},<br/>
        month     = {7},<br/>
        doi       = {10.24963/ijcai.2020/687},<br/>
        url       = {https://doi.org/10.24963/ijcai.2020/687},<br/>
      }

- layout: paper
    paper-type: inproceedings
    selected: y
    year: 2020
    img: ijcai2020
    title: "MuLaN: Multilingual Label propagatioN for Word Sense Disambiguation"
    authors: "Edoardo Barba, Luigi Procopio, Niccolò Campolungo <strong>Tommaso Pasini</strong> and Roberto Navigli"
    booktitle: Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence (IJCAI-2020)
    doc-url: https://www.ijcai.org/Proceedings/2020/0531.pdf
    venue: conference\
    abstract: >
      The knowledge acquisition bottleneck strongly affects the creation of multilingual sense-annotated data, hence
      limiting the power of supervised systems when applied to multilingual Word Sense Disambiguation. In this paper,
      we propose a semi-supervised approach based upon a novel label propagation scheme, which, by jointly leveraging
      contextualized word embeddings and the multilingual information enclosed in a knowledge base, projects sense
      labels from a high-resource language, i.e., English, to lower-resourced ones. Backed by several experiments, we
      provide empirical evidence that our automatically created datasets are of a higher quality than those generated
      by other competitors and lead a supervised model to achieve state-of-the-art performances in all multilingual
      Word Sense Disambiguation tasks. We make our datasets available for research purposes at
      https://github.com/SapienzaNLP/mulan.
    bibtex: |
      @inproceedings{barba-et-al-2020-mulan,
        title     = {{MuLaN: Multilingual Label propagatioN for Word Sense Disambiguation}},<br/>
        author    = {Barba, Edoardo and Procopio, Luigi and Campolungo, Niccolò and Pasini, Tommaso and Navigli, Roberto}, <br/>
        booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
                     Artificial Intelligence, {IJCAI-20}},<br/>
        publisher = {International Joint Conferences on Artificial Intelligence Organization},<br/>
        pages     = {3837--3844},<br/>
        year      = {2020},<br/>
        month     = {7},<br/>
        doi       = {10.24963/ijcai.2020/531},<br/>
        url       = {https://doi.org/10.24963/ijcai.2020/531},<br/>
      }
-
  layout: paper
  paper-type: inproceedings
  selected: y
  year: 2020
  img: acl2020
  title: "CluBERT: A Cluster-Based Approach for Learning Sense Distributions in Multiple Languages"
  authors: "<strong>Tommaso Pasini</strong>, Federico Scozzafava and Bianca Scarlini"
  booktitle: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.
  doc-url: https://www.researchgate.net/publication/341151563_CluBERT_A_Cluster-Based_Approach_for_Learning_Sense_Distributions_in_Multiple_Languages
  venue: conference\
  abstract: >
    Knowing the Most Frequent Sense (MFS) of a word has been proved to help Word Sense Disambiguation (WSD)
    models significantly. However, the scarcity of sense-annotated data makes it difficult to induce a reliable
    and high-coverage distribution of the meanings in a language vocabulary.
    To address this issue, in this paper we present CluBERT, an automatic and multilingual approach for inducing
    the distributions of word senses from a corpus of raw sentences.
    Our experiments show that CluBERT learns distributions over English senses that are of higher quality than
    those extracted by alternative approaches.
    When used to induce the MFS of a lemma, CluBERT attains state-of-the-art results on the English Word Sense
    Disambiguation tasks and helps to improve the disambiguation performance of two off-the-shelf WSD models.
    Moreover, our distributions also prove to be effective in other languages, beating all their alternatives
    for computing the MFS on the multilingual WSD tasks.
    We release our sense distributions in five different languages at https://github.com/SapienzaNLP/clubert.
  bibtex: |
    @inproceedings{pasini-etal-2020,<br/>
        title = {{CluBERT: A Cluster-Based Approach for Learning Sense Distributions in Multiple Languages}},<br/>
        author = {Pasini, Tommaso and Scozzafava, Federico, and Scarlini, Bianca},<br/>
        booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},<br/>
        year = {2020},<br/>
        month = {Jul}, <br/>
        address = {Virtual},<br/>
        publisher = {Association for Computational Linguistics}<br/>
    }
-
  layout: paper
  paper-type: inproceedings
  selected: y
  year: 2020
  img: LREC2020
  title: "Sense-Annotated Corpora for Word Sense Disambiguation in Multiple Languages and Domains"
  authors: "Bianca Scarlini, <strong>Tommaso Pasini</strong> and Roberto Navigli"
  booktitle: Proceedings of LREC.
  doc-url: http://trainomatic.org/data/LREC_2020_Scarlinietal.pdf
  venue: conference\
  abstract: >
    The knowledge acquisition bottleneck problem dramatically hampers the creation of sense-annotated
    data for Word Sense Disambiguation (WSD). Sense-annotated data are scarce for English and almost absent
    for other languages. This limits the range of action of deeplearning approaches, which today are at the
    base of any NLP task and are hungry for data. We mitigate this issue and encourage further research in
    multilingual WSD by releasing to the NLP community five large datasets annotated with word senses in five
    different languages, namely, English, French, Italian, German and Spanish, and 5 distinct datasets in
    English, each for a different semantic domain. We show that supervised WSD models trained on our data
    attain higher performance than when trained on other automaticallycreated corpora. We release all our
    data containing more than 15 million annotated instances in 5 different languages at http://trainomatic.org/onesec.
  bibtex: |
    @inproceedings{scarlini-etal-2020,<br/>
        title = {{Sense-Annotated Corpora for Word Sense Disambiguation in Multiple Languages and Domains}},<br/>
        author = "Scarlini, Bianca and Pasini, Tommaso and Navigli, Roberto",<br/>
        booktitle = "Proceedings of LREC",<br/>
        month = May,<br/>
        year = "2020",<br/>
        address = "Virtual",<br/>
        publisher = "LRE"<br/>
    }

-
  layout: paper
  paper-type: inproceedings
  selected: y
  year: 2020
  img: LREC2020
  title: "A Short Survey on Sense-Annotated Corpora"
  authors: "<strong>Tommaso Pasini</strong> and Jose Camacho-Collados"
  booktitle: Proceedings of LREC.
  doc-url: https://arxiv.org/abs/1802.04744
  venue: conference\
  abstract: >
    Large sense-annotated datasets are increasingly necessary for training deep supervised systems in Word Sense Disambiguation. However, gathering high-quality sense-annotated data for as many instances as possible is a laborious and expensive task. This has led to the proliferation of automatic and semi-automatic methods for overcoming the so-called knowledge-acquisition bottleneck. In this short survey we present an overview of sense-annotated corpora, annotated either manually- or (semi)automatically, that are currently available for different languages and featuring distinct lexical resources as inventory of senses, i.e. WordNet, Wikipedia, BabelNet. Furthermore, we provide the reader with general statistics of each dataset and an analysis of their specific features.
  bibtex: |
    @inproceedings{pasini-and-camachocollados-2020,<br/>
        title = {{A Short Survey on Sense-Annotated Corpora}},<br/>
        author = {Pasini, Tommaso and Camacho-Collados, Jose},<br/>
        booktitle = "Proceedings of LREC",<br/>
        month = May,<br/>
        year = "2020",<br/>
        address = "Virtual",<br/>
        publisher = "LRE"<br/>
    }

-
  layout: paper
  paper-type: inproceedings
  selected: y
  year: 2020
  img: aaai2020
  title: "SensEmBERT: Context-Enhanced Sense Embeddings for Multilingual Word Sense Disambiguation"
  authors: "Bianca Scarlini, <strong>Tommaso Pasini</strong> and Roberto Navigli"
  booktitle: Proceedings of AAAI.
  doc-url: https://pasinit.github.io/papers/scarlini_etal_aaai2020.pdf # https://www.aclweb.org/anthology/P19-1069.pdf
  venue: conference\
  abstract: >
    Contextual representations of words derived by neural language models have proven to effectively encode the subtle distinctions
    that might occur between different meanings of the same word. However, these representations are not tied to a semantic network,
    hence they leave the word meanings implicit and thereby neglect the information that can be derived from the knowledge base itself.
    In this paper, we propose SensEmBERT, a knowledge-based approach that brings together the expressive power of language modelling and
    the vast amount of knowledge contained in a semantic network to produce high-quality latent semantic representations of word meanings in multiple languages.
    Our vectors lie in a space comparable with that of contextualized word embeddings, thus allowing a word occurrence to be easily linked to
    its meaning by applying a simple nearest neighbour approach.
    We show that, whilst not relying on manual semantic annotations, SensEmBERT is able to either achieve or surpass state-of-the-art
    results attained by most of the supervised neural approaches on the English Word Sense Disambiguation task.
    When scaling to other languages, our representations prove to be equally effective as their English counterpart and
    outperform the existing state of the art on all the Word Sense Disambiguation multilingual datasets.
    The embeddings are released in five different languages at http://sensembert.org.
  bibtex: |
    @inproceedings{scarlini-etal-2020,<br/>
        title = "{{SensEmBERT:Context-Enhanced Sense Embeddings for Multilingual Word Sense Disambiguation}}",<br/>
        author = "Scarlini, Bianca and Pasini, Tommaso and Navigli, Roberto",<br/>
        booktitle = "Proceedings of AAAI",<br/>
        month = Feb,<br/>
        year = "2020",<br/>
        address = "New York, USA",<br/>
        publisher = "AAAI"<br/>
    }
-
  layout: paper
  paper-type: inproceedings
  selected: y
  year: 2020
  img: aaai2020
  title: "CSI: A Coarse Sense Inventory for 85% Word Sense Disambiguation"
  authors: "Caterina Lacerra, Michele Bevilacqua, <strong>Tommaso Pasini</strong> and Roberto Navigli"
  booktitle: Proceedings of AAAI.
  doc-url: https://pasinit.github.io/papers/lacerra_etal_aaai2020.pdf #https://www.aclweb.org/anthology/P19-1069.pdf
  venue: conference\
  abstract: >
    Word Sense Disambiguation (WSD) is the task of associating a word in context with one of its meanings. While many
    works in the past have focused on raising the state of the art, none has even come close to achieving an F-score
    in the 80% ballpark when using WordNet as its sense inventory.
    We contend that one of the main reasons for this failure is the excessively fine granularity of this inventory,
    resulting in senses that are hard to differentiate between, even for an experienced human annotator.
    In this paper we cope with this long-standing problem by introducing Coarse Sense Inventory (CSI),
    obtained by linking WordNet concepts to a new set of 45 labels. The results show that the coarse granularity of CSI
    leads a WSD model to achieve 85.9% F1, while maintaining a high expressive power. Our set of labels also exhibits
    ease of use in tagging and a descriptiveness that other coarse inventories lack, as demonstrated in two annotation
    tasks which we performed. Moreover, a few-shot evaluation proves that the class-based nature of CSI allows the model
    to generalise over unseen or under-represented words.
  bibtex: >
    @inproceedings{lacerra-etal-2020,<br/>
        title = "{{CSI: A Coarse Sense Inventory for 85% Word Sense Disambiguation}}",<br/>
        author = "Lacerra, Caterina and Bevilacqua, Michele and Pasini, Tommaso  and
          Navigli, Roberto",<br/>
        booktitle = "Proceedings of AAAI",<br/>
        month = Feb,<br/>
        year = "2020",<br/>
        address = "New York, USA",<br/>
        publisher = "AAAI"<br/>
    }
-
  layout: article
  paper-type: article
  selected: y
  year: "2020"
  img: aij2020
  title: "Train-O-Matic: Supervised Word Sense Disambiguation with No (Manual) Effort"
  authors: "<strong>Tommaso Pasini</strong> and Roberto Navigli"
  journal: "Artificial Intelligence Journal"
  journal-url: https://doi.org/10.1016/j.artint.2019.103215
  bibtex: >
    @article{pasini2020train,<br/>
        title = "{{Train-O-Matic: Supervised Word Sense Disambiguation with no (manual) effort}}",<br/>
        author = "{Pasini, Tommaso and Navigli, Roberto}",<br/>
        journal = "{Artificial Intelligence}",<br/>
        volume = {279},<br/>
        pages = {103--215},<br/>
        year = {2020},<br/>
        publisher = {Elsevier}<br/>
    }
  abstract: >
    Word Sense Disambiguation (WSD) is the task of associating the correct meaning with a word in a given context. WSD provides explicit semantic information that is beneficial to several down stream applications, such as: question answering, semantic parsing and hypernym extraction. Unfortunately, WSD suffers from the well-known knowledge acquisition bottleneck problem: it is very expensive, in terms of both time and money, to acquire semantic annotations for a large number of sentences.
    To address this blocking issue we present Train-O-Matic, a knowledge-based and language-independent approach that is able to provide millions of training instances annotated automatically with word meanings. The approach is fully automatic, i.e., no human intervention is required, and the only type of human knowledge used is a task-independent WordNet-like resource.
    Moreover, as the sense distribution in the training set is pivotal to boosting the performance of WSD systems, we also present two unsupervised and language-independent methods that automatically induce a sense distribution when given a simple corpus of sentences. We show that when the learned distributions are taken into account for generating the training sets, the performance of supervised methods is further enhanced.
    Experiments have proven that Train-O-Matic on its own, and also coupled with word sense distribution learning methods, lead a supervised system to achieve state-of-the-art performance consistently across gold standard datasets and languages. Importantly, we show how our sense distribution learning techniques aid Train-O-Matic to scale well over domains, without any extra human effort.
    To encourage future research, we release all the training sets in 5 different languages and the sense distributions for each domain of SemEval 2013 and SemEval 2015 at http://trainomatic.org.

-
  layout: paper
  paper-type: inproceedings
  selected: y
  year: 2019
  img: acl2019
  title: "Just “OneSeC” for Producing Multilingual Sense-Annotated Data"
  authors: "Bianca Scarlini, <strong>Tommaso Pasini</strong> and Roberto Navigli"
  booktitle: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics.
  doc-url: https://www.aclweb.org/anthology/P19-1069.pdf
  venue: conference
  abstract: >
    The well-known problem of knowledge acquisition is one of the biggest issues in Word Sense Disambiguation (WSD), where annotated data are still scarce in English and almost absent in other languages. In this paper we formulate the assumption of One Sense per Wikipedia Category and present OneSeC, a language-independent method for the automatic extraction of hundreds of thousands of sentences in which a target word is tagged with its meaning. Our automatically-generated data consistently lead a supervised WSD model to state-of-the-art performance when compared with other automatic and semi-automatic methods. Moreover, our approach outperforms its competitors on multilingual and domain-specific settings, where it beats the existing state of the art on all languages and most domains. All the training data are available for research purposes at http://trainomatic.org/onesec.
  bibtex: >
    @inproceedings{scarlini-etal-2019-just,<br/>
        title = "Just {``}{O}ne{S}e{C}{''} for Producing Multilingual Sense-Annotated Data",<br/>
        author = "Scarlini, Bianca  and
          Pasini, Tommaso  and
          Navigli, Roberto",<br/>
        booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",<br/>
        month = jul,<br/>
        year = "2019",<br/>
        address = "Florence, Italy",<br/>
        publisher = "Association for Computational Linguistics",<br/>
        url = "https://www.aclweb.org/anthology/P19-1069",<br/>
        doi = "10.18653/v1/P19-1069",<br/>
        pages = "699--709"<br/>
    }
-
  layout: paper
  paper-type: inproceedings
  selected: y
  year: 2017
  img: emnlp2017
  title: "Train-O-Matic: Large-Scale Supervised Word Sense Disambiguation in Multiple Languages without Manual Training Data"
  authors: "<strong>Tommaso Pasini</strong> and Roberto Navigli"
  booktitle: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing.
  doc-url: https://www.aclweb.org/anthology/D17-1008.pdf
  venue: conference\
  abstract: >
     Annotating large numbers of sentences with senses is the heaviest requirement of current Word Sense Disambiguation. We present Train-O-Matic, a language-independent method for generating millions of sense-annotated training instances for virtually all meanings of words in a language’s vocabulary. The approach is fully automatic: no human intervention is required and the only type of human knowledge used is a WordNet-like resource. Train-O-Matic achieves consistently state-of-the-art performance across gold standard datasets and languages, while at the same time removing the burden of manual annotation. All the training data is available for research purposes at http://trainomatic.org.
  bibtex: >
    @inproceedings{pasini-navigli-2017-train,<br/>
        title = "Train-O-{M}atic: Large-Scale Supervised Word Sense Disambiguation in Multiple Languages without Manual Training Data",<br/>
        author = "Pasini, Tommaso  and
          Navigli, Roberto",<br/>
        booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",<br/>
        month = sep,<br/>
        year = "2017",<br/>
        address = "Copenhagen, Denmark",<br/>
        publisher = "Association for Computational Linguistics",<br/>
        url = "https://www.aclweb.org/anthology/D17-1008",<br/>
        doi = "10.18653/v1/D17-1008",<br/>
        pages = "78--88"<br/>
    }
-
  layout: paper
  paper-type: inproceedings
  selected: y
  year: 2014
  img: acl2014
  title: "Two Is Bigger (and Better) Than One: the Wikipedia Bitaxonomy Project."
  authors: "Tiziano Flati, Daniele Vannella, <strong>Tommaso Pasini</strong> and Roberto Navigli"
  booktitle: Proceedings of the 52th Annual Meeting of the Association for Computational Linguistics.
  doc-url: https://www.aclweb.org/anthology/P14-1089.pdf
  venue: conference\
  abstract: >
    We present WiBi, an approach to the
    automatic creation of a bitaxonomy for
    Wikipedia, that is, an integrated taxonomy of Wikipage pages and categories.
    We leverage the information available in
    either one of the taxonomies to reinforce
    the creation of the other taxonomy. Our
    experiments show higher quality and coverage than state-of-the-art resources like
    DBpedia, YAGO, MENTA, WikiNet and
    WikiTaxonomy. WiBi is available at
    http://wibitaxonomy.org.
  bibtex: >
    @inproceedings{flati-etal-2014-two,<br/>
        title = "Two Is Bigger (and Better) Than One: the {W}ikipedia Bitaxonomy Project",<br/>
        author = "Flati, Tiziano  and
          Vannella, Daniele  and
          Pasini, Tommaso  and
          Navigli, Roberto",<br/>
        booktitle = "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",<br/>
        month = jun,<br/>
        year = "2014",<br/>
        address = "Baltimore, Maryland",<br/>
        publisher = "Association for Computational Linguistics",<br/>
        url = "https://www.aclweb.org/anthology/P14-1089",<br/>
        doi = "10.3115/v1/P14-1089",<br/>
        pages = "945--955"<br/>
    }
-
  layout: paper
  paper-type: inproceedings
  selected: y
  year: 2018
  img: acl2018
  title: "SemEval-2018 task 9: Hypernym discovery."
  authors: "Jose Camacho-Collados, Claudio Delli Bovi, Luis Espinosa-Anke, Sergio Oramas, <strong>Tommaso Pasini</strong>, Enrico Santus, Vered Shwartz, Roberto Navigli, Horacio Saggio"
  booktitle: Proceedings of the 12th International Workshop on Semantic Evaluation (SemEval-2018).
  doc-url: https://repositori.upf.edu/handle/10230/35249
  venue: conference\
  abstract: >
     Knowing the correct distribution of senses within a corpus can potentially boost the performance of Word Sense Disambiguation (WSD) systems by many points. We present two fully automatic and language-independent methods for computing the distribution of senses given a raw corpus of sentences. Intrinsic and extrinsic evaluations show that our methods outperform the current state of the art in sense distribution learning and the strongest baselines for the most frequent sense in multiple languages and on domain-specific test sets. Our sense distributions are available at http://trainomatic.org.
  bibtex: >
    @inproceedings{camacho-collados-etal-2018-semeval,
        title = "{S}em{E}val-2018 Task 9: Hypernym Discovery",<br/>
        author = "Camacho-Collados, Jose  and
          Delli Bovi, Claudio  and
          Espinosa-Anke, Luis  and
          Oramas, Sergio  and
          Pasini, Tommaso  and
          Santus, Enrico  and
          Shwartz, Vered  and
          Navigli, Roberto  and
          Saggion, Horacio",
        booktitle = "Proceedings of The 12th International Workshop on Semantic Evaluation",<br/>
        year = "2018", <br/>
        doi = "10.18653/v1/S18-1115",<br/>
        pages = "712--724",<br/>
    }
-
  layout: paper
  paper-type: inproceedings
  selected: y
  year: 2018
  img: aaai2018
  title: "Two Knowledge-based Methods for High-Performance Sense Distribution Learning"
  authors: "<strong>Tommaso Pasini</strong> and Roberto Navigli"
  booktitle: Proceedings of Thirty-Second AAAI Conference on Artificial Intelligence.
  doc-url: https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16406/16090
  venue: conference\
  abstract: >
     Knowing the correct distribution of senses within a corpus can potentially boost the performance of Word Sense Disambiguation (WSD) systems by many points. We present two fully automatic and language-independent methods for computing the distribution of senses given a raw corpus of sentences. Intrinsic and extrinsic evaluations show that our methods outperform the current state of the art in sense distribution learning and the strongest baselines for the most frequent sense in multiple languages and on domain-specific test sets. Our sense distributions are available at http://trainomatic.org.
  bibtex: >
    @inproceedings{pasini2018two,<br/>
      title={Two knowledge-based methods for high-performance sense distribution learning},<br/>
      author={Pasini, Tommaso and Navigli, Roberto},<br/>
      booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},<br/>
      year={2018}<br/>
    }
-
  layout: paper
  paper-type: inproceedings
  selected: y
  year: 2018
  img: aaai2018
  title: "Huge Automatically Extracted Training Sets for Multilingual Word Sense Disambiguation"
  authors: "<strong>Tommaso Pasini</strong>, Francesco Maria Elia and Roberto Navigli"
  booktitle: Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018).
  doc-url: https://www.aclweb.org/anthology/L18-1268/
  venue: conference\
  abstract: >
    We release to the community six large-scale sense-annotated datasets in multiple language to pave the way for supervised multilingual
    Word Sense Disambiguation. Our datasets cover all the nouns in the English WordNet and their translations in other languages for a
    total of millions of sense-tagged sentences . Experiments prove that these corpora can be effectively used as training sets for supervised
    WSD systems, surpassing the state of the art for low-resourced languages and providing competitive results for English, where manually
    annotated training sets are accessible. The data is available at trainomatic.org.
  bibtex: >
    @inproceedings{pasini-etal-2018-huge,<br/>
        title = "Huge Automatically Extracted Training-Sets for Multilingual Word {S}ense{D}isambiguation",<br/>
        author = "Pasini, Tommaso  and
          Elia, Francesco  and
          Navigli, Roberto",<br/>
        booktitle = "Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)",<br/>
        month = may,<br/>
        year = "2018",<br/>
        address = "Miyazaki, Japan",<br/>
        publisher = "European Language Resources Association (ELRA)",<br/>
        url = "https://www.aclweb.org/anthology/L18-1268",<br/>
    }
-
  layout: article
  paper-type: article
  selected: y
  year: "2016"
  img: aij2016
  title: "MultiWiBi: The multilingual Wikipedia bitaxonomy project"
  authors: "Tiziano Flati, Daniele Vannella, <strong>Tommaso Pasini</strong> and Roberto Navigli"
  journal: "Artificial Intelligence"
  journal-url: "https://www.sciencedirect.com/science/article/abs/pii/S0004370216300959"
  abstract: >
    We present MultiWiBi, an approach to the automatic creation of two integrated taxonomies for Wikipedia pages and categories written in different languages. In order to create both taxonomies in an arbitrary language, we first build them in English and then project the two taxonomies to other languages automatically, without the help of language-specific resources or tools. The process crucially leverages a novel algorithm which exploits the information available in either one of the taxonomies to reinforce the creation of the other taxonomy. Our experiments show that the taxonomical information in MultiWiBi is characterized by a higher quality and coverage than state-of-the-art resources like DBpedia, YAGO, MENTA, WikiNet, LHD and WikiTaxonomy, also across languages. MultiWiBi is available online at http://wibitaxonomy.org/multiwibi.
  bibtex: >
   @Article{flati2016multiwibi,<br/>
     title={MultiWiBi: The multilingual Wikipedia bitaxonomy project},<br/>
     author={Flati, Tiziano and Vannella, Daniele and Pasini, Tommaso and Navigli, Roberto},<br/>
     journal={Artificial Intelligence},<br/>
     volume={241},<br/>
     pages={66--102},<br/>
     year={2016},<br/>
     publisher={Elsevier}<br/>
   }
